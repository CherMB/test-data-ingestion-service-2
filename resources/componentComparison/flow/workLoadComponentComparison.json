{
    "definition": {
        "id": "work-load-compare",
        "title": "Work load",
        "sub_title": "Comparison",
        "breadCrumbTitle": "{{.orgName}}",
        "post_process_function_name": "workload component comparison",
        "column_details": {
            "column1": "Name",
            "column2": "Average work items in progress"
        },
        "header_field": "totalValue",
        "compare_common_section_details": {
            "type": 2,
            "show_legends": false,
            "is_component_compare": true,
            "orientation": 0,
            "append_unit": " ",
            "tooltip_formatter": 1,
            "color_scheme": [
                {
                    "color0": "#E19090",
                    "color1": "#DE3838"
                },
                {
                    "color0": "#62B0FF",
                    "color1": "#1C67FF"
                },
                {
                    "color0": "#E2C2A4",
                    "color1": "#E78730"
                },
                {
                    "color0": "#9FB6C1",
                    "color1": "#577688"
                }
            ],
            "light_color_scheme": [
                {
                    "color0": "#FF9E9C",
                    "color1": "#DE4643"
                },
                {
                    "color0": "#38B3FB",
                    "color1": "#047ED0"
                },
                {
                    "color0": "#FFD3AA",
                    "color1": "#E8A263"
                },
                {
                    "color0": "#AFBFC6",
                    "color1": "#7692A3"
                }
            ]
        }
    },
    "queries": {
        "flowWorkLoad": {
            "alias": "flow_metrics",
            "query": {
                "size": 0,
                "query": {
                    "bool": {
                        "filter": [
                            {
                                "term": {
                                    "org_id": "{{.orgId}}"
                                }
                            },
                            {
                                "term": {
                                    "deleted": "false"
                                }
                            }
                        ]
                    }
                },
                "aggs": {
                    "workload_component_comparison": {
                        "terms": {
                            "field": "component_id",
                            "size": 10000
                        },
                        "aggs": {
                            "work_load_counts": {
                                "scripted_metric": {
                                    "params": {
                                        "startDate": "{{.dateHistogramMin}}",
                                        "endDate": "{{.dateHistogramMax}}",
                                        "aggrBy": "{{.aggrBy}}",
                                        "timeZone": "{{.timeZone}}"
                                    },
                                    "init_script": "state.uniqueIssuesMap = [:];",
                                    "map_script": "def map = state.uniqueIssuesMap;def key = doc.org_id.value + '_' + doc.component_id.value + '_' + doc.automation_id.value + '_' + doc.run_id.value + '_' + doc.issue_key.value + doc.flow_item.value;def v = ['timestamp':doc['timestamp'].getValue().toEpochSecond() * 1000, 'created_at':doc['created_at'].getValue().toEpochSecond() * 1000, 'updated_at':doc['updated_at'].getValue().toEpochSecond() * 1000, 'org_id':doc.org_id.value, 'component_id':doc.component_id.value, 'issue_key':doc.issue_key.value, 'flow_item':doc.flow_item.value, 'completed_at':doc['completed_at'].size() == 0 ? null:doc['completed_at'].getValue().toEpochSecond() * 1000,'clh':params['_source']['change_log_history']];map.put(key, v);",
                                    "combine_script": "return state.uniqueIssuesMap;",
                                    "reduce_script": "HashMap getDateBuckets(LocalDate startDate, LocalDate endDate, String aggrBy){def OutputMap = new HashMap();def dateIntervalsMap = new HashMap();TreeMap dates = new TreeMap();if (aggrBy.equals('week')){def prevDate = startDate;dates.put(startDate.toString(), new LinkedHashMap());LocalDate firstMonday = startDate.with(TemporalAdjusters.next(DayOfWeek.MONDAY));while (firstMonday.compareTo(endDate) <= 0){def curDate = firstMonday;long diffMillis = Duration.between(prevDate.atStartOfDay(), curDate.atStartOfDay()).toMillis();dateIntervalsMap.put(prevDate.toString(), diffMillis);prevDate = curDate;dates.put(firstMonday.toString(), new LinkedHashMap());firstMonday = firstMonday.plusDays(7);}long diffForLastDate = Duration.between(prevDate.atStartOfDay(), endDate.atStartOfDay()).toMillis();dateIntervalsMap.put(prevDate.toString(), diffForLastDate);} else if (aggrBy.equals('day')){long days = ChronoUnit.DAYS.between(startDate, endDate);long oneDayInMilli = 86400000;for (long i = 0; i <= days; i++){LocalDate date = startDate.plusDays(i);dates.put(date.toString(), new LinkedHashMap());dateIntervalsMap.put(date.toString(), oneDayInMilli);}} else if (aggrBy.equals('month')){def prevDate = startDate;dates.put(startDate.toString(), new LinkedHashMap());LocalDate firstDayOfMonth = startDate.with(TemporalAdjusters.firstDayOfMonth());if (startDate.isAfter(firstDayOfMonth)){firstDayOfMonth = firstDayOfMonth.plusMonths(1);}while (firstDayOfMonth.compareTo(endDate) <= 0){def curDate = firstDayOfMonth;long diffMillis = Duration.between(prevDate.atStartOfDay(), curDate.atStartOfDay()).toMillis();dateIntervalsMap.put(prevDate.toString(), diffMillis);prevDate = curDate;dates.put(firstDayOfMonth.toString(), new LinkedHashMap());firstDayOfMonth = firstDayOfMonth.plusMonths(1);}long diffForLastDate = Duration.between(prevDate.atStartOfDay(), endDate.atStartOfDay()).toMillis();dateIntervalsMap.put(prevDate.toString(), diffForLastDate);} else if (aggrBy.equals('duration')){dates.put(startDate.toString(), new LinkedHashMap());long diffMillis = Duration.between(startDate.atStartOfDay(), endDate.atStartOfDay()).toMillis();dateIntervalsMap.put(startDate.toString(), diffMillis);}OutputMap.put('dates', dates);OutputMap.put('intervals', dateIntervalsMap);return OutputMap}def issuesMap = new HashMap();def resultMap = new HashMap();def workLoadIssuesTotal = new HashSet();def formatterISO = DateTimeFormatter.ISO_LOCAL_DATE;LocalDate stDt = LocalDate.parse(params.startDate, formatterISO);LocalDate endDt = LocalDate.parse(params.endDate, formatterISO);def dateInfoMap = getDateBuckets(stDt, endDt, params.aggrBy);def dateBuckets = dateInfoMap.get('dates');def dateIntervals = dateInfoMap.get('intervals');for (a in states){if (a != null){for (i in a.keySet()){def record = a.get(i);def key = record.org_id + '_' + record.issue_key;if (issuesMap.containsKey(key)){def lastRecord = issuesMap.get(key);if (lastRecord.updated_at < record.updated_at){issuesMap.put(key, record);}} else{issuesMap.put(key, record);}}}}SimpleDateFormat dfDateTime = new SimpleDateFormat('yyyy-MM-dd HH:mm:ss');for (ele in issuesMap.keySet()){def curIssue = issuesMap.get(ele);def clh = curIssue.clh;def statusTimestamps = clh.status_timestamp;if (statusTimestamps != null){for (int i = 0; i < statusTimestamps.size(); i++){def curStatusTimestampMap = statusTimestamps[i];if (curStatusTimestampMap.get('type') == 'IN_PROGRESS'){def wipStartTimeString = curStatusTimestampMap.get('start_time');def wipEndTimeString = curStatusTimestampMap.get('end_time');Date wipST = dfDateTime.parse(wipStartTimeString);long wipStartTime = wipST.getTime();Date wipET;long wipEndTime;if (wipEndTimeString != ''){wipET = dfDateTime.parse(wipEndTimeString);wipEndTime = wipET.getTime();}def issueFlowItem = curIssue.flow_item;def issueKey = curIssue.issue_key;for (date in dateBuckets.keySet()){LocalDate bucketDate = LocalDate.parse(date, formatterISO);ZonedDateTime zonedBucketDate = bucketDate.atStartOfDay(ZoneId.of(params.timeZone));Instant zonedBucketDateInstant = zonedBucketDate.toInstant();long bucketDateEpoch = zonedBucketDateInstant.toEpochMilli();def flowItemMap = dateBuckets.get(date);if (flowItemMap.size() == 0){flowItemMap.put('DEFECT', 0);flowItemMap.put('FEATURE', 0);flowItemMap.put('RISK', 0);flowItemMap.put('TECH_DEBT', 0);flowItemMap.put('DEFECT_SET', new HashSet());flowItemMap.put('FEATURE_SET', new HashSet());flowItemMap.put('RISK_SET', new HashSet());flowItemMap.put('TECH_DEBT_SET', new HashSet());}if ((wipStartTime < bucketDateEpoch && (wipEndTimeString == '' || (wipEndTime >= bucketDateEpoch))) || (wipStartTime >= bucketDateEpoch && wipStartTime < (bucketDateEpoch + dateIntervals.get(date)))){workLoadIssuesTotal.add(issueKey);def curFlowItemHashSet = flowItemMap.get(issueFlowItem + '_SET');curFlowItemHashSet.add(issueKey);flowItemMap.put(issueFlowItem, curFlowItemHashSet.size());}}}}}}resultMap.put('headerValue', workLoadIssuesTotal.size());resultMap.put('dates', dateBuckets);return resultMap;"
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}